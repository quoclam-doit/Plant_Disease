# BÃO CÃO Váº¤N Äá»€ Ká»¸ THUáº¬T: TRIá»‚N KHAI MODEL MAMBATSR

**Sinh viÃªn:** [TÃªn cá»§a báº¡n]  
**NgÃ y:** 10/11/2025  
**Äá» tÃ i:** PhÃ¢n loáº¡i bá»‡nh cÃ¢y trá»“ng sá»­ dá»¥ng MambaTSR

---

## 1. TÃ“M Táº®T Váº¤N Äá»€

Trong quÃ¡ trÃ¬nh triá»ƒn khai model **MambaTSR** (State Space Model) theo yÃªu cáº§u cá»§a tháº§y Ä‘á»ƒ phÃ¢n loáº¡i bá»‡nh trÃªn dataset PlantVillage (39 classes), em Ä‘Ã£ gáº·p pháº£i **váº¥n Ä‘á» khÃ´ng tÆ°Æ¡ng thÃ­ch vá» pháº§n cá»©ng** giá»¯a GPU RTX 5060 Ti vÃ  framework PyTorch phiÃªn báº£n á»•n Ä‘á»‹nh hiá»‡n táº¡i.

### Váº¥n Ä‘á» cá»‘t lÃµi:

- **GPU cá»§a em:** NVIDIA GeForce RTX 5060 Ti (16GB VRAM)
- **Compute Capability:** sm_120 (Architecture: Blackwell - tháº¿ há»‡ má»›i nháº¥t 2025)
- **PyTorch stable:** Chá»‰ há»— trá»£ Ä‘áº¿n sm_90 (RTX 4090)
- **Káº¿t quáº£:** KhÃ´ng thá»ƒ cháº¡y báº¥t ká»³ CUDA operation nÃ o

---

## 2. QUÃ TRÃŒNH KHáº®C PHá»¤C ÄÃƒ THá»°C HIá»†N

### 2.1. CÃ i Ä‘áº·t mÃ´i trÆ°á»ng cÆ¡ báº£n âœ…

```
âœ“ Python 3.11.9
âœ“ PyTorch 2.6.0 + CUDA 12.4
âœ“ Visual Studio Build Tools 2022
âœ“ CUDA Toolkit 12.4
âœ“ Dependencies: timm, einops, fvcore, tensorboard
```

### 2.2. BiÃªn dá»‹ch CUDA kernels cho Windows âœ…

MambaTSR sá»­ dá»¥ng custom CUDA kernels (selective_scan) Ä‘Æ°á»£c thiáº¿t káº¿ cho Linux/GCC. Em Ä‘Ã£:

1. **Fix M_LOG2E macro** - ThÃªm Ä‘á»‹nh nghÄ©a cho Windows MSVC (8 files)
2. **Fix BOOL_SWITCH template** - Thay tháº¿ lambda báº±ng explicit template instantiation (6 files)
3. **Compile thÃ nh cÃ´ng** vá»›i `TORCH_CUDA_ARCH_LIST = "8.9+PTX"`

```bash
âœ“ selective_scan_cuda_core compiled successfully
âœ“ Module imports without errors
```

### 2.3. XÃ¡c minh váº¥n Ä‘á» GPU incompatibility âŒ

**Test 1: Tensor creation**

```python
x = torch.randn(2, 16, 32).cuda()
# âœ“ ThÃ nh cÃ´ng - tensor Ä‘Æ°á»£c táº¡o trÃªn GPU
```

**Test 2: PyTorch operations**

```python
x = torch.randn(1, 3, 32, 32).cuda()
y = F.max_pool2d(x, kernel_size=2, stride=2)
# âŒ RuntimeError: CUDA error: no kernel image is available for execution
```

**Lá»—i chÃ­nh thá»©c tá»« PyTorch:**

```
UserWarning: NVIDIA GeForce RTX 5060 Ti with CUDA capability sm_120
is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities:
sm_50, sm_60, sm_61, sm_70, sm_75, sm_80, sm_86, sm_90
```

### 2.4. CÃ¡c giáº£i phÃ¡p Ä‘Ã£ thá»­ âŒ

| Giáº£i phÃ¡p                 | Káº¿t quáº£                        | LÃ½ do tháº¥t báº¡i                                         |
| ------------------------- | ------------------------------ | ------------------------------------------------------ |
| CUDA_FORCE_PTX_JIT=1      | âŒ Tháº¥t báº¡i                    | PyTorch khÃ´ng cÃ³ PTX code cho base operations          |
| PyTorch nightly build     | âŒ Conflict                    | Dependency incompatibilities vá»›i torchvision           |
| Downgrade CUDA driver     | âŒ KhÃ´ng kháº£ thi               | Hardware khÃ´ng thá»ƒ fake compute capability             |
| Upgrade CUDA Toolkit 13.0 | âŒ Tháº¥t báº¡i                    | selective_scan kernels khÃ´ng tÆ°Æ¡ng thÃ­ch vá»›i CUDA 13.0 |
| CPU training              | âš ï¸ Kháº£ thi nhÆ°ng khÃ´ng thá»±c táº¿ | Cháº­m hÆ¡n ~200x, máº¥t vÃ i tuáº§n training                  |

---

## 3. PHÃ‚N TÃCH Ká»¸ THUáº¬T

### 3.1. Táº¡i sao RTX 5060 Ti khÃ´ng hoáº¡t Ä‘á»™ng?

PyTorch distribution (pre-built wheels) Ä‘Æ°á»£c compile vá»›i danh sÃ¡ch compute capabilities cá»‘ Ä‘á»‹nh:

- **PyTorch 2.6.0:** Support sm_50 â†’ sm_90
- **RTX 5060 Ti:** Requires sm_120 (Blackwell architecture)
- **Gap:** 3 tháº¿ há»‡ kiáº¿n trÃºc (Hopper â†’ Blackwell)

**Báº±ng chá»©ng kiá»ƒm tra thá»±c táº¿:**

```python
>>> import torch
>>> torch.cuda.get_arch_list()
['sm_50', 'sm_60', 'sm_61', 'sm_70', 'sm_75', 'sm_80', 'sm_86', 'sm_90']
#                                                                   â†‘
#                                                         Dá»ªNG á» sm_90
```

**Cáº£nh bÃ¡o chÃ­nh thá»©c tá»« PyTorch:**

```
UserWarning: NVIDIA GeForce RTX 5060 Ti with CUDA capability sm_120
is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities:
sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90
```

**Äá»‘i chiáº¿u vá»›i NVIDIA documentation** _(https://developer.nvidia.com/cuda-gpus)_:

| Compute Cap | Architecture   | NÄƒm       | PyTorch 2.6.0        |
| ----------- | -------------- | --------- | -------------------- |
| sm_50-86    | Maxwell-Ampere | 2014-2020 | âœ… Support           |
| sm_90       | Hopper         | 2022      | âœ… Support           |
| **sm_120**  | **Blackwell**  | **2025**  | **âŒ KHÃ”NG support** |

### 3.2. Táº¡i sao khÃ´ng thá»ƒ dÃ¹ng PTX JIT?

- PyTorch pre-built **khÃ´ng bao gá»“m PTX intermediate representation** cho base CUDA operations
- Chá»‰ cÃ³ **binary kernels** cho cÃ¡c architectures Ä‘Æ°á»£c support
- sm_120 quÃ¡ khÃ¡c biá»‡t â†’ khÃ´ng thá»ƒ backward compatible

### 3.3. Váº¥n Ä‘á» CUDA Toolkit Version Compatibility

**Cáº¥u hÃ¬nh hiá»‡n táº¡i (ÄÃƒ ÄÃšNG):**

```
CUDA Driver: 13.0 (system level, GPU yÃªu cáº§u)
CUDA Toolkit: 12.4 (development tools, compatible)
PyTorch: 2.6.0+cu124 (matching vá»›i toolkit)
selective_scan: âœ“ Compile thÃ nh cÃ´ng vá»›i CUDA 12.4
```

**Táº¡i sao KHÃ”NG THá»‚ upgrade CUDA Toolkit lÃªn 13.0?**

1. **selective_scan kernels khÃ´ng tÆ°Æ¡ng thÃ­ch vá»›i CUDA 13.0**

   - Code Ä‘Æ°á»£c phÃ¡t triá»ƒn cho CUDA 11.x - 12.x
   - CUDA 13.0 cÃ³ breaking API changes
   - Compiler (nvcc 13.0) reject má»™t sá»‘ syntax patterns cÅ©

2. **Best practice: Driver > Toolkit lÃ  OK**

   - CUDA Driver 13.0 (GPU side) backward compatible
   - CUDA Toolkit 12.4 (compile tools) hoáº¡t Ä‘á»™ng hoÃ n háº£o
   - PyTorch 2.6.0 build cho cu124, khÃ´ng cÃ³ cu130 version

3. **Lá»—i Ä‘iá»ƒn hÃ¬nh náº¿u dÃ¹ng CUDA 13.0:**
   ```bash
   nvcc fatal: Unknown option
   error: namespace 'thrust' has no member
   Template instantiation failures
   ```

**Káº¿t luáº­n:** Váº¥n Ä‘á» KHÃ”NG PHáº¢I á»Ÿ CUDA toolkit version, mÃ  á»Ÿ PyTorch binary khÃ´ng support sm_120.

### 3.4. Model MambaTSR Ä‘áº·c thÃ¹

```python
Super_Mamba Architecture:
â”œâ”€â”€ ConvNet (preprocessing) - Sá»­ dá»¥ng PyTorch base ops (max_pool2d âŒ)
â”œâ”€â”€ 6x VSSBlock - Sá»­ dá»¥ng selective_scan custom kernel (âœ“ Ä‘Ã£ compile)
â””â”€â”€ Classifier - Sá»­ dá»¥ng Linear layers (âŒ CUDA matmul)
```

**Váº¥n Ä‘á»:** Máº·c dÃ¹ custom kernels compile Ä‘Æ°á»£c, nhÆ°ng PyTorch base operations (conv, pool, matmul) váº«n fail.

---

## 4. GIáº¢I PHÃP KHáº¢ THI

### 4.1. â­ Build PyTorch tá»« source (KHUYáº¾N NGHá»Š Náº¾U CÃ“ THá»œI GIAN)

**Æ¯u Ä‘iá»ƒm:**

- âœ… Giáº£i quyáº¿t triá»‡t Ä‘á»ƒ váº¥n Ä‘á»
- âœ… Táº­n dá»¥ng Ä‘áº§y Ä‘á»§ RTX 5060 Ti (16GB VRAM)
- âœ… Tá»‘c Ä‘á»™ training tá»‘i Æ°u

**NhÆ°á»£c Ä‘iá»ƒm:**

- â±ï¸ Máº¥t 2-4 giá» compile
- ğŸ’¾ Cáº§n ~20GB disk space
- ğŸ”§ Phá»©c táº¡p, dá»… lá»—i

**Steps:**

```bash
1. Install Visual Studio 2022 + CUDA 12.4 âœ“ (Ä‘Ã£ cÃ³)
2. Clone PyTorch source tá»« GitHub
3. Set TORCH_CUDA_ARCH_LIST="8.9;9.0;12.0"
4. python setup.py install (2-4 hours)
```

### 4.2. â­â­â­ Google Colab vá»›i GPU miá»…n phÃ­ (KHUYáº¾N NGHá»Š NHáº¤T)

**Æ¯u Ä‘iá»ƒm:**

- âœ… Miá»…n phÃ­, khÃ´ng setup
- âœ… GPU T4 (sm_75) - 100% compatible
- âœ… 12 hours/session, Ä‘á»§ train 50-100 epochs
- âœ… CÃ³ notebook sáºµn em Ä‘Ã£ chuáº©n bá»‹: `Plant_Disease_MambaTSR_Colab.ipynb`

**NhÆ°á»£c Ä‘iá»ƒm:**

- â±ï¸ Session timeout sau 12h (cÃ³ thá»ƒ reconnect)
- ğŸ“¤ Cáº§n upload dataset (~2GB)

**Note:** Em biáº¿t tháº§y khÃ´ng cho phÃ©p Colab trong bÃ i ná»™p, nhÆ°ng cÃ³ thá»ƒ dÃ¹ng Ä‘á»ƒ:

- Verify model architecture hoáº¡t Ä‘á»™ng Ä‘Ãºng
- Cháº¡y thá»­ nghiá»‡m ban Ä‘áº§u
- So sÃ¡nh káº¿t quáº£ trÆ°á»›c khi chuyá»ƒn sang giáº£i phÃ¡p khÃ¡c

### 4.3. â­â­ ThuÃª Cloud GPU tÆ°Æ¡ng thÃ­ch

**Platforms:**

- **Lambda Labs:** $0.50/hour (RTX 4090, sm_90) âœ“
- **Vast.ai:** $0.30-0.60/hour (cÃ¡c GPU compatible)
- **AWS EC2 P3/G4:** $1-3/hour

**Æ¯á»›c tÃ­nh chi phÃ­:**

- Training 100 epochs: ~4-6 giá»
- Total cost: $2-5 (ráº¥t reasonable)

### 4.4. â­ Chuyá»ƒn sang model khÃ¡c (FALLBACK)

Náº¿u khÃ´ng thá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» GPU, Ä‘á» xuáº¥t chuyá»ƒn sang:

**Option A: CNN Ensemble (Ä‘Ã£ implement)**

```
âœ“ ResNet50, DenseNet121, EfficientNet-B3, Inception-V3
âœ“ ÄÃ£ train xong, cÃ³ káº¿t quáº£
âœ“ Compatible vá»›i má»i GPU
```

**Option B: Vision Transformer variants**

```
- ViT (Vision Transformer)
- Swin Transformer
- EfficientFormer
â†’ CÅ©ng state-of-the-art, PyTorch native support
```

### 4.5. âŒ Giáº£i phÃ¡p KHÃ”NG kháº£ thi

| Giáº£i phÃ¡p                  | Táº¡i sao khÃ´ng?                                           |
| -------------------------- | -------------------------------------------------------- |
| Train trÃªn CPU             | Máº¥t 2-4 tuáº§n, khÃ´ng practical cho deadline               |
| MÆ°á»£n GPU cÅ©                | Em khÃ´ng cÃ³ access                                       |
| Docker/WSL2                | Váº«n cÃ¹ng PyTorch version, cÃ¹ng váº¥n Ä‘á»                    |
| PyTorch nightly            | Dependency conflicts, unstable                           |
| Upgrade CUDA Toolkit 13.0  | selective_scan khÃ´ng compile Ä‘Æ°á»£c vá»›i CUDA 13.0          |
| Downgrade CUDA Driver 12.4 | RTX 5060 Ti driver 13.0 tá»‘i thiá»ƒu (hardware requirement) |

---

## 5. Äá»€ XUáº¤T VÃ€ XIN Ã KIáº¾N THáº¦Y

Em xin tháº§y hÆ°á»›ng dáº«n vÃ  cho phÃ©p má»™t trong cÃ¡c phÆ°Æ¡ng Ã¡n sau:

### PhÆ°Æ¡ng Ã¡n 1: XIN PHÃ‰P CHUYá»‚N Äá»”I MODEL (Æ¯U TIÃŠN)

- âœ… Chuyá»ƒn tá»« MambaTSR sang **Swin Transformer** hoáº·c **EfficientFormer**
- âœ… Váº«n lÃ  state-of-the-art, cÃ¹ng Ã½ tÆ°á»Ÿng attention mechanism
- âœ… Compatible vá»›i hardware hiá»‡n cÃ³
- âœ… CÃ³ thá»ƒ báº¯t Ä‘áº§u ngay, khÃ´ng máº¥t thá»i gian setup

**LÃ½ do:**

- MambaTSR lÃ  research model ráº¥t má»›i (2024), hardware compatibility chÆ°a Ä‘áº§y Ä‘á»§
- Swin/EfficientFormer cÅ©ng top-tier, Ä‘Æ°á»£c industry cháº¥p nháº­n rá»™ng rÃ£i
- Váº«n thá»ƒ hiá»‡n Ä‘Æ°á»£c kiáº¿n thá»©c vá» modern architectures

### PhÆ°Æ¡ng Ã¡n 2: BUILD PYTORCH Tá»ª SOURCE

- â±ï¸ Cáº§n 2-4 giá» compile + testing
- ğŸ”§ Em sáº½ thá»±c hiá»‡n vá»›i há»— trá»£ tá»« AI assistant
- âš ï¸ Risk: CÃ³ thá»ƒ fail, máº¥t thá»i gian

**Timeline estimate:**

- Build PyTorch: 4 giá»
- Test & debug: 2 giá»
- Training MambaTSR: 6-8 giá»
- Total: ~14-16 giá»

### PhÆ°Æ¡ng Ã¡n 3: Sá»¬ Dá»¤NG CLOUD GPU

- ğŸ’° Chi phÃ­: ~$2-5 cho toÃ n bá»™ project
- â±ï¸ Setup: 30 phÃºt
- âœ… Guarantee success

**Em cÃ³ thá»ƒ tá»± chi tráº£ náº¿u tháº§y Ä‘á»“ng Ã½ phÆ°Æ¡ng Ã¡n nÃ y.**

### PhÆ°Æ¡ng Ã¡n 4: Káº¾T Há»¢P

- Train MambaTSR trÃªn Colab/Cloud Ä‘á»ƒ **verify architecture + thu káº¿t quáº£**
- Parallel: Implement Swin Transformer local Ä‘á»ƒ **backup**
- Submit: Model nÃ o tá»‘t hÆ¡n + phÃ¢n tÃ­ch so sÃ¡nh

---

## 6. Káº¾T QUáº¢ ÄÃƒ CÃ“ (Sáº´N SÃ€NG Ná»˜P)

Trong quÃ¡ trÃ¬nh lÃ m theo yÃªu cáº§u ban Ä‘áº§u, em Ä‘Ã£ hoÃ n thÃ nh:

### 6.1. CNN Ensemble Model âœ“

```
Models: ResNet50, DenseNet121, EfficientNet-B3, Inception-V3
Dataset: PlantVillage (39 classes, ~50,000 images)
Results:
  - Individual best: 98.2% (EfficientNet-B3)
  - Ensemble: 98.7%
Files ready:
  âœ“ Plant_Disease_YOLOv4_Ensemble.ipynb
  âœ“ Trained weights in models/ folder
  âœ“ Training histories & visualizations
```

### 6.2. MambaTSR Implementation âœ“

```
Setup complete:
  âœ“ Architecture code verified
  âœ“ CUDA kernels compiled (Windows compatible)
  âœ“ Dataset pipeline ready
  âœ“ Training loop implemented
  âœ“ Colab notebook prepared

Blocked by: GPU hardware incompatibility (documented above)
```

### 6.3. Documentation âœ“

```
âœ“ README files
âœ“ Setup guides
âœ“ Technical reports
âœ“ This issue analysis
```

---

## 7. THÃ”NG TIN THÃŠM

### 7.1. Tham kháº£o ká»¹ thuáº­t

- **PyTorch CUDA Compatibility:** https://pytorch.org/get-started/locally/
- **NVIDIA Compute Capabilities:** https://developer.nvidia.com/cuda-gpus
- **MambaTSR Paper:** "MambaTSR: State Space Model for..." (2024)
- **Báº±ng chá»©ng chi tiáº¿t:** `DANG_CHUNG_PYTORCH_CUDA_COMPATIBILITY.md` (file Ä‘Ã­nh kÃ¨m)

### 7.2. Hardware details

```
GPU: NVIDIA GeForce RTX 5060 Ti
VRAM: 16GB GDDR6
Compute Capability: 12.0 (sm_120)
CUDA Driver: 13.0
Architecture: Blackwell (2025, latest generation)
```

### 7.3. Software environment

```
OS: Windows 11
Python: 3.11.9
PyTorch: 2.6.0+cu124 (stable, latest)
CUDA Toolkit: 12.4
Visual Studio: 2022 Build Tools
```

---

## 8. Káº¾T LUáº¬N

Em Ä‘Ã£ ná»— lá»±c tá»‘i Ä‘a Ä‘á»ƒ implement Ä‘Ãºng yÃªu cáº§u cá»§a tháº§y vá» model MambaTSR. Tuy nhiÃªn, do:

1. **Hardware quÃ¡ má»›i** (RTX 5060 Ti released 2025)
2. **PyTorch stable chÆ°a support** (cáº§n build from source)
3. **Timeline project bá»‹ áº£nh hÆ°á»Ÿng**

Em ráº¥t mong Ä‘Æ°á»£c tháº§y:

- âœ… **Cháº¥p nháº­n Ä‘á»•i model** sang alternative tÆ°Æ¡ng Ä‘Æ°Æ¡ng (Swin/EfficientFormer)
- âœ… **Cho phÃ©p dÃ¹ng cloud/Colab** Ä‘á»ƒ cháº¡y MambaTSR
- âœ… **HÆ°á»›ng dáº«n thÃªm** náº¿u tháº§y cÃ³ giáº£i phÃ¡p khÃ¡c

Em cam káº¿t sáº½:

- ğŸ“š HoÃ n thÃ nh tá»‘t vá»›i phÆ°Æ¡ng Ã¡n tháº§y chá»n
- ğŸ“Š TrÃ¬nh bÃ y Ä‘áº§y Ä‘á»§ technical analysis
- ğŸ’ª Há»c há»i vÃ  kháº¯c phá»¥c váº¥n Ä‘á» nÃ y cho tÆ°Æ¡ng lai

**Em xin chÃ¢n thÃ nh cáº£m Æ¡n tháº§y Ä‘Ã£ Ä‘á»c bÃ¡o cÃ¡o nÃ y!**

---

**Phá»¥ lá»¥c:**

- File log chi tiáº¿t: `MAMBATSR_SETUP_GUIDE.md`
- **Báº±ng chá»©ng compatibility issue:** `DANG_CHUNG_PYTORCH_CUDA_COMPATIBILITY.md` â­
- Notebook Colab sáºµn sÃ ng: `Plant_Disease_MambaTSR_Colab.ipynb`
- Notebook local (blocked): `Plant_Disease_MambaTSR.ipynb`
- CNN Ensemble (working): `Plant_Disease_YOLOv4_Ensemble.ipynb`

---

_BÃ¡o cÃ¡o Ä‘Æ°á»£c táº¡o ngÃ y 10/11/2025_  
_Vá»›i sá»± há»— trá»£ ká»¹ thuáº­t tá»« GitHub Copilot_
