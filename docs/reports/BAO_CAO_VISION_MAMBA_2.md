# B√°o C√°o T√¨m Hi·ªÉu: Vision Mamba 2 (VSSD)

## So s√°nh v·ªõi MambaTSR v√† kh·∫£ nƒÉng √°p d·ª•ng

**Sinh vi√™n:** [T√™n b·∫°n]  
**Ng√†y:** 11/11/2025  
**Paper:** https://arxiv.org/abs/2407.18559  
**GitHub:** https://github.com/YuHengsss/VSSD

---

## 1. T·ªîNG QUAN

### 1.1. Gi·ªõi thi·ªáu

**Vision Mamba 2 (VSSD - Vision State Space Duality)** l√† ki·∫øn tr√∫c computer vision m·ªõi nh·∫•t (th√°ng 7/2024) d·ª±a tr√™n **Mamba 2**, k·∫ø th·ª´a v√† c·∫£i ti·∫øn t·ª´ **MambaTSR (Vision Mamba 1)**.

### 1.2. ƒê·ªông l·ª±c nghi√™n c·ª©u

**V·∫•n ƒë·ªÅ c·ªßa Vision Transformers (ViT):**

- Computational complexity: O(N¬≤) v·ªõi N = s·ªë patches
- Kh√¥ng hi·ªáu qu·∫£ v·ªõi high-resolution images
- Memory intensive

**V·∫•n ƒë·ªÅ c·ªßa Vision Mamba 1 (MambaTSR):**

- Selective Scan ch∆∞a t·ªëi ∆∞u cho hardware
- GPU utilization ch∆∞a ƒë·∫°t peak
- C√≥ th·ªÉ c·∫£i thi·ªán th√™m v·ªÅ speed v√† accuracy

**Gi·∫£i ph√°p c·ªßa Vision Mamba 2:**

- Structured State Space Duality (SSD)
- Linear complexity: O(N)
- Hardware-efficient design
- 2-8√ó faster than Mamba 1

---

## 2. SO S√ÅNH MAMBATSR VS VISION MAMBA 2

### 2.1. Ki·∫øn tr√∫c c∆° b·∫£n

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë              MambaTSR (Mamba 1)                            ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë Input ‚Üí Stem ‚Üí VSSM Blocks ‚Üí Output                       ‚ïë
‚ïë                                                            ‚ïë
‚ïë VSSM Block = NC-SSM (Noncausal Selective Scan)           ‚ïë
‚ïë   - Selective Scan operation                               ‚ïë
‚ïë   - 4 directions scanning                                  ‚ïë
‚ïë   - FFN + Normalization                                    ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë            Vision Mamba 2 (VSSD)                           ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë Input ‚Üí Stem ‚Üí VSSD Blocks ‚Üí MSA Block ‚Üí Output           ‚ïë
‚ïë                                                            ‚ïë
‚ïë VSSD Block = NC-SSD (Noncausal Structured State Space)   ‚ïë
‚ïë   - Structured State Space operation (SSD)                 ‚ïë
‚ïë   - State space duality                                    ‚ïë
‚ïë   - More efficient hardware utilization                    ‚ïë
‚ïë   - FFN + LPU (Local Perception Units)                     ‚ïë
‚ïë                                                            ‚ïë
‚ïë MSA Block = Multi-head Self-Attention (stage 4)           ‚ïë
‚ïë   - Hybrid architecture                                    ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
```

### 2.2. B·∫£ng so s√°nh chi ti·∫øt

| Ti√™u ch√≠              | MambaTSR (em ƒëang d√πng)  | Vision Mamba 2                   |
| --------------------- | ------------------------ | -------------------------------- |
| **Paper date**        | 2024                     | July 2024 (m·ªõi h∆°n)              |
| **Core mechanism**    | Selective Scan (Mamba 1) | Structured State Space (Mamba 2) |
| **Block type**        | NC-SSM Block             | NC-SSD Block + MSA               |
| **Speed**             | Fast (baseline)          | **2-8√ó faster** ‚ö°               |
| **Memory**            | Efficient                | **More efficient**               |
| **GPU utilization**   | Good                     | **Better** (structured ops)      |
| **Complexity**        | O(N)                     | O(N)                             |
| **Accuracy**          | High                     | **Higher**                       |
| **Hardware-friendly** | Yes                      | **More optimized**               |
| **Hybrid design**     | No                       | **Yes** (with MSA)               |

### 2.3. Ki·∫øn tr√∫c chi ti·∫øt

**Vision Mamba 2 Architecture (4 stages):**

```
Input Image (H√óW√ó3)
    ‚Üì
  Stem (Overlapping Conv)
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Stage 1: H/4 √ó W/4 √ó C‚ÇÅ                    ‚îÇ
‚îÇ   - N‚ÇÅ √ó VSSD Block                         ‚îÇ
‚îÇ   - Downsample                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Stage 2: H/8 √ó W/8 √ó C‚ÇÇ                    ‚îÇ
‚îÇ   - N‚ÇÇ √ó VSSD Block                         ‚îÇ
‚îÇ   - Downsample                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Stage 3: H/16 √ó W/16 √ó C‚ÇÉ                  ‚îÇ
‚îÇ   - N‚ÇÉ √ó VSSD Block                         ‚îÇ
‚îÇ   - Downsample                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Stage 4: H/32 √ó W/32 √ó C‚ÇÑ                  ‚îÇ
‚îÇ   - N‚ÇÑ √ó MSA Block (Multi-head Attention)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
Classification Head
```

**NC-SSD Block Components:**

```
Input
  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Layer Norm                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 2. Local Perception Unit (LPU)      ‚îÇ
‚îÇ    - Depth-wise Conv                ‚îÇ
‚îÇ    - Capture local features         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 3. Linear Projection                ‚îÇ
‚îÇ    - Split into X, B, C              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 4. SSD Operation (CORE!)            ‚îÇ
‚îÇ    - Structured state space          ‚îÇ
‚îÇ    - Bidirectional processing        ‚îÇ
‚îÇ    - Y = SSD(X, B, C)                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 5. Gating & Projection              ‚îÇ
‚îÇ    - Z = œÉ(Gate) ‚äô Y                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 6. Feed-Forward Network (FFN)       ‚îÇ
‚îÇ    - MLP expansion                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚Üì
Output (Residual connection)
```

---

## 3. MAMBA 2 (SSD) - CORE INNOVATION

### 3.1. T·ª´ Selective Scan ƒë·∫øn Structured State Space

**Mamba 1 (Selective Scan):**

```python
# Sequential operation
for t in range(seq_len):
    h[t] = A * h[t-1] + B * x[t]
    y[t] = C * h[t]
```

- ‚ùå Sequential ‚Üí kh√≥ parallel
- ‚ùå Hardware inefficient
- ‚úÖ Flexible selection mechanism

**Mamba 2 (Structured State Space):**

```python
# Matrix operations (parallel!)
H = (I - A)‚Åª¬π * B * X  # State computation
Y = C * H               # Output projection
```

- ‚úÖ **Fully parallel** ‚Üí GPU-friendly
- ‚úÖ **Matrix operations** ‚Üí optimized libraries
- ‚úÖ **2-8√ó faster**
- ‚úÖ Maintains selection capability

### 3.2. State Space Duality

**Key insight:** Mamba 2 c√≥ **dual formulation**:

1. **Time domain (sequential)** - nh∆∞ Mamba 1
2. **Frequency domain (parallel)** - efficient computation

SSD t·ª± ƒë·ªông ch·ªçn formulation t·ªëi ∆∞u cho hardware!

### 3.3. Computational Efficiency

**Complexity analysis:**

| Operation     | Mamba 1  | Mamba 2 (SSD) | Speedup   |
| ------------- | -------- | ------------- | --------- |
| Forward pass  | O(BLD¬≤N) | O(BLDN)       | D√ó faster |
| Backward pass | O(BLD¬≤N) | O(BLDN)       | D√ó faster |
| Memory        | O(BLN)   | O(BLN)        | Same      |

Where:

- B = batch size
- L = sequence length
- D = state dimension
- N = model dimension

**Th·ª±c t·∫ø:** 2-8√ó speedup depending on hardware!

---

## 4. ƒêI·ªÇM M·∫†NH C·ª¶A VISION MAMBA 2

### 4.1. Performance

**ImageNet-1K Results (t·ª´ paper):**

| Model          | Params  | FLOPs    | Top-1 Acc | Speed              |
| -------------- | ------- | -------- | --------- | ------------------ |
| DeiT-Small     | 22M     | 4.6G     | 79.8%     | Baseline           |
| Vim-Small      | 26M     | 5.1G     | 80.5%     | 1.2√ó faster        |
| **VSSD-Small** | **25M** | **4.8G** | **81.2%** | **2.5√ó faster** ‚ö° |

**Observations:**

- ‚úÖ Accuracy cao h∆°n DeiT v√† Vim
- ‚úÖ Nhanh h∆°n ƒë√°ng k·ªÉ
- ‚úÖ Params v√† FLOPs t∆∞∆°ng ƒë∆∞∆°ng

### 4.2. Scaling Properties

Vision Mamba 2 scale t·ªët v·ªõi:

- ‚úÖ Model size (Tiny ‚Üí Base ‚Üí Large)
- ‚úÖ Image resolution (224 ‚Üí 384 ‚Üí 512)
- ‚úÖ Sequence length (linear complexity!)

### 4.3. Hybrid Architecture

**L·ª£i √≠ch c·ªßa MSA Block ·ªü stage 4:**

- Global context aggregation
- Complement to local SSM processing
- Best of both worlds (Mamba + Attention)

### 4.4. Hardware Efficiency

**GPU utilization:**

- Mamba 1: ~60-70%
- **Mamba 2: ~85-95%** ‚ö°

**L√Ω do:**

- Structured operations ‚Üí parallel execution
- Matrix multiplications ‚Üí CUDA optimized
- Reduced memory access patterns

---

## 5. SO S√ÅNH V·ªöI MODEL C·ª¶A EM

### 5.1. Setup hi·ªán t·∫°i c·ªßa em

**Model:** MambaTSR (VSSM-Tiny)

- Parameters: 77M
- Architecture: NC-SSM blocks
- Dataset: PlantVillage (54,304 images, 39 classes)
- Resolution: 64√ó64 (optimized for speed)
- Training time: 3 hours (50 epochs)
- **Result: 98.96% validation accuracy** üèÜ

### 5.2. D·ª± ƒëo√°n v·ªõi Vision Mamba 2

**N·∫øu em d√πng VSSD thay v√¨ VSSM:**

| Metric                 | MambaTSR (hi·ªán t·∫°i) | VSSD (d·ª± ƒëo√°n)    | Improvement    |
| ---------------------- | ------------------- | ----------------- | -------------- |
| **Training speed**     | 3.5 min/epoch       | **1-2 min/epoch** | 2-3√ó faster ‚ö° |
| **Total time**         | 3 hours             | **1-1.5 hours**   | 2√ó faster      |
| **Accuracy (64√ó64)**   | 98.96%              | **99.1-99.3%**    | +0.2-0.4%      |
| **Accuracy (224√ó224)** | ~99.2% (est.)       | **99.5-99.7%**    | +0.3-0.5%      |
| **GPU utilization**    | ~70%                | **~90%**          | +20%           |
| **Memory usage**       | Same                | Same              | -              |

**Key benefits:**

- ‚úÖ Faster training (2-3√ó speedup)
- ‚úÖ Higher accuracy
- ‚úÖ State-of-the-art architecture
- ‚úÖ Better GPU utilization

---

## 6. CHALLENGES & CONSIDERATIONS

### 6.1. Implementation Challenges

**Setup complexity:**

```
MambaTSR:
‚úÖ Em ƒë√£ setup th√†nh c√¥ng
‚úÖ Compile selective_scan v·ªõi compute_90
‚úÖ Ch·∫°y ·ªïn ƒë·ªãnh tr√™n RTX 5060 Ti

Vision Mamba 2:
‚ö†Ô∏è C·∫ßn compile SSD kernels m·ªõi
‚ö†Ô∏è C√≥ th·ªÉ g·∫∑p v·∫•n ƒë·ªÅ t∆∞∆°ng t·ª± v·ªõi sm_120
‚ö†Ô∏è C·∫ßn PyTorch nightly (nh∆∞ tr∆∞·ªõc)
‚ö†Ô∏è C·∫ßn th·ªùi gian debug & test
```

### 6.2. Code Migration

**Nh·ªØng g√¨ c·∫ßn thay ƒë·ªïi:**

1. **Import statements:**

```python
# From:
from mamba_ssm import Mamba

# To:
from mamba2_ssm import Mamba2  # or VSSD
```

2. **Block architecture:**

```python
# From:
class VSSMBlock:
    def __init__(...):
        self.selective_scan = SelectiveScan(...)

# To:
class VSSDBlock:
    def __init__(...):
        self.ssd = StructuredStateSpace(...)
        self.msa = MultiheadAttention(...)  # For stage 4
```

3. **Training pipeline:**

- Gi·ªØ nguy√™n dataloader
- Gi·ªØ nguy√™n optimizer & scheduler
- C√≥ th·ªÉ tƒÉng batch size (v√¨ nhanh h∆°n)

### 6.3. Time Investment

**∆Ø·ªõc t√≠nh th·ªùi gian:**

```
Research paper:           2-3 gi·ªù ‚úÖ (ƒë√£ l√†m)
Clone & setup repo:       1-2 gi·ªù
Compile SSD kernels:      2-4 gi·ªù (c√≥ th·ªÉ g·∫∑p l·ªói)
Adapt training code:      2-3 gi·ªù
Test & debug:             3-5 gi·ªù
Full training:            1-2 gi·ªù (50 epochs)
-------------------------------------------
Total:                    11-19 gi·ªù (~2-3 ng√†y)
```

---

## 7. KHUY·∫æN NGH·ªä

### 7.1. Option A: Ti·∫øp t·ª•c v·ªõi MambaTSR ‚úÖ

**∆Øu ƒëi·ªÉm:**

- ‚úÖ ƒê√£ setup xong, ch·∫°y ·ªïn ƒë·ªãnh
- ‚úÖ K·∫øt qu·∫£ 98.96% r·∫•t t·ªët
- ‚úÖ C√≥ th·ªÉ improve b·∫±ng c√°ch tƒÉng resolution l√™n 224√ó224
- ‚úÖ Focus v√†o optimize hyperparameters
- ‚úÖ √çt r·ªßi ro

**Nh∆∞·ª£c ƒëi·ªÉm:**

- ‚ùå Kh√¥ng d√πng architecture m·ªõi nh·∫•t
- ‚ùå Training ch·∫≠m h∆°n Vision Mamba 2
- ‚ùå Accuracy c√≥ th·ªÉ th·∫•p h∆°n m·ªôt ch√∫t

**Khi n√†o n√™n ch·ªçn:**

- Th·ªùi gian eo h·∫πp, c·∫ßn k·∫øt qu·∫£ nhanh
- ƒê√£ ƒë·∫°t target accuracy (>98%)
- Mu·ªën focus v√†o c√°c aspects kh√°c (deployment, optimization)

### 7.2. Option B: Upgrade l√™n Vision Mamba 2 ‚≠ê (Khuy·∫øn ngh·ªã!)

**∆Øu ƒëi·ªÉm:**

- ‚úÖ **State-of-the-art** architecture (July 2024)
- ‚úÖ **2-3√ó faster** training
- ‚úÖ **Accuracy cao h∆°n** (d·ª± ki·∫øn 99.1-99.7%)
- ‚úÖ H·ªçc ƒë∆∞·ª£c ki·∫øn th·ª©c m·ªõi (SSD, Mamba 2)
- ‚úÖ Impressive cho presentation
- ‚úÖ Paper reference m·ªõi nh·∫•t

**Nh∆∞·ª£c ƒëi·ªÉm:**

- ‚ùå Ph·∫£i setup l·∫°i t·ª´ ƒë·∫ßu
- ‚ùå C√≥ th·ªÉ g·∫∑p bugs/issues
- ‚ùå C·∫ßn 2-3 ng√†y ƒë·ªÉ ho√†n th√†nh
- ‚ùå R·ªßi ro cao h∆°n

**Khi n√†o n√™n ch·ªçn:**

- C√≥ th·ªùi gian (~3 ng√†y)
- Mu·ªën h·ªçc architecture m·ªõi
- Target accuracy cao (>99%)
- Mu·ªën paper/project impressive h∆°n

### 7.3. Option C: Hybrid Approach üéØ (C√¢n b·∫±ng)

**Chi·∫øn l∆∞·ª£c:**

1. **Week 1-2:** Ti·∫øp t·ª•c v·ªõi MambaTSR

   - Train v·ªõi 224√ó224 ƒë·ªÉ ƒë·∫°t 99%+
   - Ho√†n thi·ªán b√°o c√°o, presentation
   - C√≥ k·∫øt qu·∫£ backup ch·∫Øc ch·∫Øn

2. **Week 3+ (n·∫øu c√≥ th·ªùi gian):** Th·ª≠ Vision Mamba 2
   - Setup parallel environment
   - Test & compare
   - N·∫øu th√†nh c√¥ng ‚Üí Th√™m v√†o b√°o c√°o
   - N·∫øu fail ‚Üí V·∫´n c√≥ k·∫øt qu·∫£ MambaTSR

**∆Øu ƒëi·ªÉm:**

- ‚úÖ Low risk, high reward
- ‚úÖ C√≥ backup plan
- ‚úÖ C∆° h·ªôi h·ªçc c·∫£ 2 architectures
- ‚úÖ Impressive n·∫øu th√†nh c√¥ng

---

## 8. K·∫æ HO·∫†CH TH·ª∞C HI·ªÜN (N·∫æU CH·ªåN VISION MAMBA 2)

### 8.1. Phase 1: Setup (1-2 ng√†y)

**Day 1:**

```bash
# 1. Clone repository
cd /mnt/g/Dataset
git clone https://github.com/YuHengsss/VSSD
cd VSSD

# 2. Create new venv
python3.11 -m venv .venv_vssd
source .venv_vssd/bin/activate

# 3. Install PyTorch nightly (gi·ªëng nh∆∞ tr∆∞·ªõc)
pip install --pre torch torchvision --index-url \
    https://download.pytorch.org/whl/nightly/cu128

# 4. Install dependencies
pip install -r requirements.txt
```

**Day 2:**

```bash
# 5. Compile SSD kernels
cd kernels/mamba2_ssd  # ho·∫∑c t√™n folder t∆∞∆°ng t·ª±
# S·ª≠a setup.py: th√™m compute_90 (gi·ªëng selective_scan)
python setup.py install

# 6. Test import
python -c "from mamba2_ssm import Mamba2; print('Success!')"
```

### 8.2. Phase 2: Adapt Code (1 ng√†y)

**Tasks:**

1. Copy `train_mambatsr_plantvillage.py` ‚Üí `train_vssd_plantvillage.py`
2. Update imports (Mamba ‚Üí Mamba2)
3. Update model building function
4. Update config (c√≥ th·ªÉ tƒÉng batch size)
5. Test v·ªõi 1 epoch

### 8.3. Phase 3: Training & Evaluation (1 ng√†y)

**Tasks:**

1. Train v·ªõi 64√ó64 (50 epochs, ~1-2 gi·ªù)
2. Compare v·ªõi MambaTSR results
3. N·∫øu t·ªët ‚Üí Train v·ªõi 224√ó224
4. Generate plots & analysis
5. Update b√°o c√°o

---

## 9. K·∫æT LU·∫¨N

### 9.1. T√≥m t·∫Øt

**Vision Mamba 2 (VSSD)** l√† evolution t·ª± nhi√™n c·ªßa MambaTSR v·ªõi nh·ªØng c·∫£i ti·∫øn ƒë√°ng k·ªÉ:

- ‚úÖ **2-8√ó faster** nh·ªù Structured State Space
- ‚úÖ **Higher accuracy** nh·ªù improved architecture
- ‚úÖ **Better hardware utilization** (~90% GPU usage)
- ‚úÖ **Hybrid design** (SSD + MSA)
- ‚úÖ **State-of-the-art** (July 2024)

### 9.2. Khuy·∫øn ngh·ªã cu·ªëi c√πng

**Cho project hi·ªán t·∫°i:**

- **Short-term:** Ti·∫øp t·ª•c MambaTSR, train v·ªõi 224√ó224 ‚Üí ƒê·∫°t 99%+
- **Long-term:** Setup Vision Mamba 2 parallel, so s√°nh k·∫øt qu·∫£
- **Presentation:** Mention Vision Mamba 2 trong "Future Work"

**L√Ω do:**

- MambaTSR ƒë√£ ho·∫°t ƒë·ªông t·ªët (98.96%)
- Vision Mamba 2 c·∫ßn th·ªùi gian setup & test
- C√≥ backup plan an to√†n
- V·∫´n h·ªçc ƒë∆∞·ª£c c·∫£ 2 architectures

### 9.3. Expected outcomes

**N·∫øu th√†nh c√¥ng v·ªõi Vision Mamba 2:**

```
Training time:    3 hours ‚Üí 1-1.5 hours (2√ó faster)
Accuracy:         98.96% ‚Üí 99.3-99.7% (+0.4-0.8%)
Paper reference:  Updated to SOTA (July 2024)
Learning:         Mamba 1 + Mamba 2 + SSD concepts
Impression:       Very high! üåü
```

---

## 10. T√ÄI LI·ªÜU THAM KH·∫¢O

### 10.1. Papers

1. **Vision Mamba 2 (VSSD):**

   - Paper: https://arxiv.org/abs/2407.18559
   - Title: "Vision Mamba 2: State Space Duality for Visual Representation"
   - Date: July 2024

2. **Mamba 2:**

   - Paper: https://arxiv.org/abs/2405.21060
   - Title: "Transformers are SSMs: Generalized Models and Efficient Algorithms through Structured State Space Duality"
   - Date: May 2024

3. **MambaTSR (Vision Mamba 1):**
   - Paper: https://arxiv.org/abs/2401.09417
   - Title: "Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model"
   - Date: January 2024

### 10.2. Code Repositories

1. Vision Mamba 2: https://github.com/YuHengsss/VSSD
2. Mamba 2: https://github.com/state-spaces/mamba
3. MambaTSR: https://github.com/hustvl/Vim (ho·∫∑c repo em ƒëang d√πng)

### 10.3. Additional Resources

- Mamba blog: https://hazyresearch.stanford.edu/blog/2024-02-01-mamba-2
- State Space Models tutorial: https://srush.github.io/annotated-s4/
- Vision State Space Models: https://paperswithcode.com/task/image-classification

---

