{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd0a255",
   "metadata": {},
   "source": [
    "# Plant Disease Detection - YOLOv4 + Ensemble Model\n",
    "## Kết hợp YOLOv4 và Ensemble Learning cho PlantVillage Dataset\n",
    "\n",
    "Thực hiện:\n",
    "1. **YOLOv4** - Object Detection cho phát hiện vùng bệnh\n",
    "2. **Ensemble Models** - Kết hợp nhiều CNN models (ResNet, EfficientNet, DenseNet) để classification\n",
    "3. **Training & Testing** - Trên PlantVillage dataset\n",
    "4. **Evaluation** - So sánh accuracy của các models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d6d981",
   "metadata": {},
   "source": [
    "## 1. Setup và Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851d7d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu130\n",
      "Torchvision version: 0.24.0+cu130\n",
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 5060 Ti\n",
      "GPU Memory: 17.10 GB\n",
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Deep Learning - PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bbce390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GPU CHECK:\n",
      "============================================================\n",
      "PyTorch version: 2.9.0+cu130\n",
      "CUDA available: True\n",
      "CUDA version: 13.0\n",
      "cuDNN version: 91200\n",
      "Number of GPUs: 1\n",
      "\n",
      "GPU 0:\n",
      "  Name: NVIDIA GeForce RTX 5060 Ti\n",
      "  Compute Capability: (12, 0)\n",
      "  Memory Total: 17.10 GB\n",
      "  Memory Allocated: 0.0000 GB\n",
      "  Memory Reserved: 0.0000 GB\n",
      "\n",
      "Testing GPU computation...\n",
      "GPU computation test successful!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU CHECK:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda if torch.cuda.is_available() else 'N/A'}\")\n",
    "print(f\"cuDNN version: {torch.backends.cudnn.version() if torch.cuda.is_available() else 'N/A'}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"\\nGPU {i}:\")\n",
    "        print(f\"  Name: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  Compute Capability: {torch.cuda.get_device_capability(i)}\")\n",
    "        print(f\"  Memory Total: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")\n",
    "        print(f\"  Memory Allocated: {torch.cuda.memory_allocated(i) / 1e9:.4f} GB\")\n",
    "        print(f\"  Memory Reserved: {torch.cuda.memory_reserved(i) / 1e9:.4f} GB\")\n",
    "    \n",
    "    # Test GPU computation\n",
    "    print(\"\\nTesting GPU computation...\")\n",
    "    x = torch.randn(1000, 1000).cuda()\n",
    "    y = torch.randn(1000, 1000).cuda()\n",
    "    z = torch.matmul(x, y)\n",
    "    print(\"GPU computation test successful!\")\n",
    "else:\n",
    "    print(\"\\nWARNING: No GPU detected!\")\n",
    "    print(\"Training will run on CPU (very slow!)\")\n",
    "    print(\"\\nTo fix, install PyTorch with CUDA support:\")\n",
    "    print(\"  pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu130\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4966078e",
   "metadata": {},
   "source": [
    "## 2. Configuration và Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be3573d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set!\n",
      "Dataset path: g:\\Dataset\\Data\\PlantVIllage\\PlantVillage-Dataset-master\n",
      "Image size: 224x224\n",
      "Batch size: 32\n",
      "Device: cuda\n",
      "Ensemble models: ['efficientnet_b3', 'resnet50', 'densenet121', 'inception_v3']\n",
      "\n",
      "Dataset path: g:\\Dataset\\Data\\PlantVIllage\\PlantVillage-Dataset-master\n",
      "Image size: 224x224\n",
      "Batch size: 32\n",
      "Device: cuda\n",
      "Ensemble models: ['efficientnet_b3', 'resnet50', 'densenet121', 'inception_v3']\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "BASE_PATH = Path(r'g:\\Dataset\\Data')\n",
    "PLANT_VILLAGE_PATH = BASE_PATH / 'PlantVIllage' / 'PlantVillage-Dataset-master'\n",
    "MODEL_SAVE_PATH = Path(r'g:\\Dataset\\models')\n",
    "MODEL_SAVE_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "# Image parameters\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "CHANNELS = 3\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 1e-4\n",
    "VALIDATION_SPLIT = 0.2\n",
    "TEST_SPLIT = 0.1\n",
    "\n",
    "# Early stopping\n",
    "PATIENCE = 10\n",
    "\n",
    "# Ensemble configuration\n",
    "ENSEMBLE_MODELS = [\n",
    "    'efficientnet_b3',\n",
    "    'resnet50',\n",
    "    'densenet121',\n",
    "    'inception_v3'\n",
    "]\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "random.seed(SEED)\n",
    "\n",
    "print(\"Configuration set!\")\n",
    "print(f\"Dataset path: {PLANT_VILLAGE_PATH}\")\n",
    "print(f\"Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Ensemble models: {ENSEMBLE_MODELS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8429e6b",
   "metadata": {},
   "source": [
    "## 3. Load và Prepare PlantVillage Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c0f2135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 39\n",
      "\n",
      "Classes:\n",
      "1. Apple___Apple_scab\n",
      "2. Apple___Black_rot\n",
      "3. Apple___Cedar_apple_rust\n",
      "4. Apple___healthy\n",
      "5. Blueberry___healthy\n",
      "6. Cherry_(including_sour)___Powdery_mildew\n",
      "7. Cherry_(including_sour)___healthy\n",
      "8. Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
      "9. Corn_(maize)___Common_rust_\n",
      "10. Corn_(maize)___Northern_Leaf_Blight\n",
      "11. Corn_(maize)___healthy\n",
      "12. Grape___Black_rot\n",
      "13. Grape___Esca_(Black_Measles)\n",
      "14. Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "15. Grape___healthy\n",
      "16. Orange___Haunglongbing_(Citrus_greening)\n",
      "17. Peach___Bacterial_spot\n",
      "18. Peach___healthy\n",
      "19. Pepper,_bell___Bacterial_spot\n",
      "20. Pepper,_bell___healthy\n",
      "21. Potato___Early_blight\n",
      "22. Potato___Late_blight\n",
      "23. Potato___healthy\n",
      "24. Raspberry___healthy\n",
      "25. Soybean___healthy\n",
      "26. Squash___Powdery_mildew\n",
      "27. Strawberry___Leaf_scorch\n",
      "28. Strawberry___healthy\n",
      "29. Tomato___Bacterial_spot\n",
      "30. Tomato___Early_blight\n",
      "31. Tomato___Late_blight\n",
      "32. Tomato___Leaf_Mold\n",
      "33. Tomato___Septoria_leaf_spot\n",
      "34. Tomato___Spider_mites Two-spotted_spider_mite\n",
      "35. Tomato___Target_Spot\n",
      "36. Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "37. Tomato___Tomato_mosaic_virus\n",
      "38. Tomato___healthy\n",
      "39. x_Removed_from_Healthy_leaves\n"
     ]
    }
   ],
   "source": [
    "# Get all class folders\n",
    "class_folders = [d for d in PLANT_VILLAGE_PATH.iterdir() if d.is_dir()]\n",
    "class_names = sorted([d.name for d in class_folders])\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"\\nClasses:\")\n",
    "for i, cls in enumerate(class_names, 1):\n",
    "    print(f\"{i}. {cls}\")\n",
    "\n",
    "# Create class to index mapping\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "idx_to_class = {idx: cls for cls, idx in class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "720a26a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 39/39 [00:00<00:00, 336.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total images: 54305\n",
      "Labels shape: (54305,)\n",
      "\n",
      "Label distribution:\n",
      "  Apple___Apple_scab: 630 images\n",
      "  Apple___Black_rot: 621 images\n",
      "  Apple___Cedar_apple_rust: 275 images\n",
      "  Apple___healthy: 1645 images\n",
      "  Blueberry___healthy: 1502 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load all image paths and labels\n",
    "def load_dataset_info(data_path):\n",
    "    \"\"\"\n",
    "    Load all image paths and their corresponding labels\n",
    "    \"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_name in tqdm(class_names, desc=\"Loading dataset\"):\n",
    "        class_path = data_path / class_name\n",
    "        class_idx = class_to_idx[class_name]\n",
    "        \n",
    "        # Get all images in this class\n",
    "        for img_path in class_path.glob('*'):\n",
    "            if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "                image_paths.append(str(img_path))\n",
    "                labels.append(class_idx)\n",
    "    \n",
    "    return np.array(image_paths), np.array(labels)\n",
    "\n",
    "# Load dataset\n",
    "X_paths, y = load_dataset_info(PLANT_VILLAGE_PATH)\n",
    "\n",
    "print(f\"\\nTotal images: {len(X_paths)}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for idx, count in zip(unique[:5], counts[:5]):\n",
    "    print(f\"  {idx_to_class[idx]}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccd62be",
   "metadata": {},
   "source": [
    "## 4. Split Dataset (Train/Val/Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c957a280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split:\n",
      "Train: 39099 images\n",
      "Validation: 9775 images\n",
      "Test: 5431 images\n",
      "\n",
      "Train ratio: 72.0%\n",
      "Val ratio: 18.0%\n",
      "Test ratio: 10.0%\n",
      "\n",
      "Train: 39099 images\n",
      "Validation: 9775 images\n",
      "Test: 5431 images\n",
      "\n",
      "Train ratio: 72.0%\n",
      "Val ratio: 18.0%\n",
      "Test ratio: 10.0%\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "# First split: Train+Val vs Test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X_paths, y, \n",
    "    test_size=TEST_SPLIT, \n",
    "    random_state=SEED, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Second split: Train vs Val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val,\n",
    "    test_size=VALIDATION_SPLIT,\n",
    "    random_state=SEED,\n",
    "    stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(\"Dataset split:\")\n",
    "print(f\"Train: {len(X_train)} images\")\n",
    "print(f\"Validation: {len(X_val)} images\")\n",
    "print(f\"Test: {len(X_test)} images\")\n",
    "print(f\"\\nTrain ratio: {len(X_train)/len(X_paths)*100:.1f}%\")\n",
    "print(f\"Val ratio: {len(X_val)/len(X_paths)*100:.1f}%\")\n",
    "print(f\"Test ratio: {len(X_test)/len(X_paths)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b844390b",
   "metadata": {},
   "source": [
    "## 5. Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbca969c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PlantDiseaseDataset class created!\n"
     ]
    }
   ],
   "source": [
    "class PlantDiseaseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for Plant Disease images\n",
    "    \"\"\"\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "print(\"PlantDiseaseDataset class created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42ff4753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transforms created!\n",
      "Training: Resize, RandomFlip, Rotation, ColorJitter, Affine, Normalize\n",
      "Validation/Test: Resize, Normalize\n"
     ]
    }
   ],
   "source": [
    "# Data transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Data transforms created!\")\n",
    "print(\"Training: Resize, RandomFlip, Rotation, ColorJitter, Affine, Normalize\")\n",
    "print(\"Validation/Test: Resize, Normalize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2729bb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataLoaders created! (workers=0, pin_memory=True)\n",
      "Train batches: 1222\n",
      "Validation batches: 306\n",
      "Test batches: 170\n"
     ]
    }
   ],
   "source": [
    "# Create PyTorch datasets\n",
    "train_dataset = PlantDiseaseDataset(X_train, y_train, transform=train_transform)\n",
    "val_dataset = PlantDiseaseDataset(X_val, y_val, transform=val_test_transform)\n",
    "test_dataset = PlantDiseaseDataset(X_test, y_test, transform=val_test_transform)\n",
    "\n",
    "# Workers: use 0 on Windows to avoid multiprocessing issues in notebooks\n",
    "import sys\n",
    "if sys.platform.startswith('win'):\n",
    "    WORKERS = 0\n",
    "else:\n",
    "    WORKERS = 4\n",
    "\n",
    "# Pin memory only if CUDA is available\n",
    "PIN_MEMORY = True if torch.cuda.is_available() else False\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=WORKERS, \n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=WORKERS, \n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=WORKERS, \n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders created! (workers={WORKERS}, pin_memory={PIN_MEMORY})\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c47cc0",
   "metadata": {},
   "source": [
    "## 6. Build Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d515f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b3:\n",
      "  Total parameters: 10,756,175\n",
      "  Trainable parameters: 10,756,175\n",
      "\n",
      "\n",
      "  Total parameters: 10,756,175\n",
      "  Trainable parameters: 10,756,175\n",
      "\n",
      "resnet50:\n",
      "  Total parameters: 24,577,127\n",
      "  Trainable parameters: 24,577,127\n",
      "\n",
      "densenet121:\n",
      "  Total parameters: 7,498,663\n",
      "  Trainable parameters: 7,498,663\n",
      "\n",
      "resnet50:\n",
      "  Total parameters: 24,577,127\n",
      "  Trainable parameters: 24,577,127\n",
      "\n",
      "densenet121:\n",
      "  Total parameters: 7,498,663\n",
      "  Trainable parameters: 7,498,663\n",
      "\n",
      "inception_v3:\n",
      "  Total parameters: 22,854,663\n",
      "  Trainable parameters: 22,854,663\n",
      "\n",
      "Model builder function created!\n",
      "inception_v3:\n",
      "  Total parameters: 22,854,663\n",
      "  Trainable parameters: 22,854,663\n",
      "\n",
      "Model builder function created!\n"
     ]
    }
   ],
   "source": [
    "def build_model(model_name, num_classes, pretrained=True):\n",
    "    \"\"\"\n",
    "    Build a transfer learning model with specified architecture\n",
    "    \"\"\"\n",
    "    if model_name == 'efficientnet_b3':\n",
    "        model = models.efficientnet_b3(pretrained=pretrained)\n",
    "        num_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.3, inplace=True),\n",
    "            nn.Linear(num_features, num_classes)\n",
    "        )\n",
    "    \n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    elif model_name == 'densenet121':\n",
    "        model = models.densenet121(pretrained=pretrained)\n",
    "        num_features = model.classifier.in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    elif model_name == 'inception_v3':\n",
    "        if pretrained:\n",
    "            # Load pretrained model with aux_logits=True (required for pretrained weights)\n",
    "            model = models.inception_v3(pretrained=True, aux_logits=True)\n",
    "            # Disable aux_logits after loading weights\n",
    "            model.aux_logits = False\n",
    "            model.AuxLogits = None\n",
    "        else:\n",
    "            model = models.inception_v3(pretrained=False, aux_logits=False)\n",
    "        \n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Test model creation\n",
    "for model_name in ENSEMBLE_MODELS:\n",
    "    model = build_model(model_name, num_classes)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Total parameters: {total_params:,}\")\n",
    "    print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "    print()\n",
    "\n",
    "print(\"Model builder function created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53f3f26",
   "metadata": {},
   "source": [
    "## 7. Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9192f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions created!\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train for one epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{running_loss/total:.4f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"\n",
    "    Validate the model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc='Validation'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, \n",
    "                scheduler, num_epochs, device, model_name, patience=10):\n",
    "    \"\"\"\n",
    "    Complete training loop with early stopping\n",
    "    \"\"\"\n",
    "    best_val_acc = 0.0\n",
    "    best_model_wts = None\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 60)\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc, _, _ = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
    "        print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        \n",
    "        # Early stopping and save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_wts = model.state_dict().copy()\n",
    "            epochs_no_improve = 0\n",
    "            \n",
    "            # Save checkpoint\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'val_loss': val_loss,\n",
    "            }, MODEL_SAVE_PATH / f'{model_name}_best.pth')\n",
    "            print(f'Saved best model with val_acc: {val_acc:.4f}')\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f'\\nEarly stopping triggered after {epoch+1} epochs')\n",
    "            break\n",
    "    \n",
    "    # Load best model weights\n",
    "    if best_model_wts is not None:\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "print(\"Training functions created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b16b50",
   "metadata": {},
   "source": [
    "## 8. Train Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69cdb5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running quick DataLoader test...\n",
      "Train batch - images shape: torch.Size([32, 3, 224, 224])\n",
      "Train batch - labels shape: torch.Size([32])\n",
      "CUDA operations OK\n",
      "DataLoader smoke test passed\n"
     ]
    }
   ],
   "source": [
    "# Quick DataLoader smoke test: fetch one batch and show shapes\n",
    "print('Running quick DataLoader test...')\n",
    "try:\n",
    "    batch = next(iter(train_loader))\n",
    "    images, labels = batch\n",
    "    print('Train batch - images shape:', images.shape)\n",
    "    print('Train batch - labels shape:', labels.shape)\n",
    "    # Move a small batch to device to ensure GPU path works\n",
    "    images = images[:2].to(device)\n",
    "    labels = labels[:2].to(device)\n",
    "    with torch.no_grad():\n",
    "        out = torch.zeros(1)  # dummy placeholder\n",
    "        if torch.cuda.is_available():\n",
    "            _ = images * 1  # quick op to ensure CUDA tensor ops succeed\n",
    "            print('CUDA operations OK')\n",
    "    print('DataLoader smoke test passed')\n",
    "except Exception as e:\n",
    "    print('DataLoader smoke test failed:', repr(e))\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb48171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Training efficientnet_b3\n",
      "======================================================================\n",
      "\n",
      "Model: efficientnet_b3\n",
      "Total parameters: 10,756,175\n",
      "Trainable parameters: 10,756,175\n",
      "\n",
      "Epoch 1/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 73/1222 [00:30<08:03,  2.38it/s, loss=1.6152, acc=59.03%]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrainable parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainable_params\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m model, history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPATIENCE\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Store model and history\u001b[39;00m\n\u001b[32m     42\u001b[39m trained_models[model_name] = model\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, model_name, patience)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m train_loss, train_acc = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m     90\u001b[39m val_loss, val_acc, _, _ = validate(model, val_loader, criterion, device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, dataloader, criterion, optimizer, device)\u001b[39m\n\u001b[32m     17\u001b[39m loss.backward()\n\u001b[32m     18\u001b[39m optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m running_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * images.size(\u001b[32m0\u001b[39m)\n\u001b[32m     21\u001b[39m _, predicted = outputs.max(\u001b[32m1\u001b[39m)\n\u001b[32m     22\u001b[39m total += labels.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Dictionary to store trained models and histories\n",
    "trained_models = {}\n",
    "training_histories = {}\n",
    "\n",
    "# Train each model\n",
    "for model_name in ENSEMBLE_MODELS:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model(model_name, num_classes, pretrained=True)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    # Train model\n",
    "    model, history = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=EPOCHS,\n",
    "        device=device,\n",
    "        model_name=model_name,\n",
    "        patience=PATIENCE\n",
    "    )\n",
    "    \n",
    "    # Store model and history\n",
    "    trained_models[model_name] = model\n",
    "    training_histories[model_name] = history\n",
    "    \n",
    "    print(f\"\\n{model_name} training completed!\")\n",
    "    print(f\"Best val_accuracy: {max(history['val_acc']):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"All models trained!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e633b",
   "metadata": {},
   "source": [
    "## 9. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b5973",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_histories' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m     plt.show()\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Plot training history\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m plot_training_history(\u001b[43mtraining_histories\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'training_histories' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_training_history(histories):\n",
    "    \"\"\"\n",
    "    Plot training history for all models\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    fig.suptitle('Training History Comparison', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax = axes[0]\n",
    "    for model_name, history in histories.items():\n",
    "        epochs_range = range(1, len(history['train_acc']) + 1)\n",
    "        ax.plot(epochs_range, history['train_acc'], label=f'{model_name} (train)', linestyle='-')\n",
    "        ax.plot(epochs_range, history['val_acc'], label=f'{model_name} (val)', linestyle='--')\n",
    "    \n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('Accuracy over Epochs')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot loss\n",
    "    ax = axes[1]\n",
    "    for model_name, history in histories.items():\n",
    "        epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "        ax.plot(epochs_range, history['train_loss'], label=f'{model_name} (train)', linestyle='-')\n",
    "        ax.plot(epochs_range, history['val_loss'], label=f'{model_name} (val)', linestyle='--')\n",
    "    \n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Loss over Epochs')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(MODEL_SAVE_PATH / 'training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(training_histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e622a4",
   "metadata": {},
   "source": [
    "## 10. Evaluate Individual Models on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abead0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model\n",
    "individual_results = {}\n",
    "\n",
    "for model_name, model in trained_models.items():\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=f'Testing {model_name}'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_loss = test_loss / total\n",
    "    test_acc = correct / total\n",
    "    test_precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    test_recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    test_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Store results\n",
    "    individual_results[model_name] = {\n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1\n",
    "    }\n",
    "    \n",
    "    print(f\"{model_name} Results:\")\n",
    "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"  Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"  Test Recall: {test_recall:.4f}\")\n",
    "    print(f\"  Test F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(individual_results).T\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Individual Model Results:\")\n",
    "print(\"=\"*70)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa34dad2",
   "metadata": {},
   "source": [
    "## 11. Build Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd518d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Ensemble model that averages predictions from multiple models\n",
    "    \"\"\"\n",
    "    def __init__(self, models_dict):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.models = nn.ModuleList(list(models_dict.values()))\n",
    "        self.num_models = len(self.models)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Get predictions from all models\n",
    "        outputs = []\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                output = model(x)\n",
    "            outputs.append(output)\n",
    "        \n",
    "        # Average predictions\n",
    "        ensemble_output = torch.stack(outputs).mean(dim=0)\n",
    "        return ensemble_output\n",
    "\n",
    "# Create ensemble\n",
    "ensemble_model = EnsembleModel(trained_models)\n",
    "ensemble_model = ensemble_model.to(device)\n",
    "ensemble_model.eval()\n",
    "\n",
    "print(\"Ensemble model created!\")\n",
    "print(f\"Number of models in ensemble: {len(trained_models)}\")\n",
    "print(f\"Models: {list(trained_models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531bdda0",
   "metadata": {},
   "source": [
    "## 12. Evaluate Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ensemble model\n",
    "print(\"Evaluating Ensemble Model...\")\n",
    "\n",
    "ensemble_model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc='Testing Ensemble'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = ensemble_model(images)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        \n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_loss = test_loss / total\n",
    "test_acc = correct / total\n",
    "test_precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "test_recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "test_f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENSEMBLE MODEL RESULTS:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "# Add ensemble results to comparison\n",
    "individual_results['Ensemble'] = {\n",
    "    'test_loss': test_loss,\n",
    "    'test_accuracy': test_acc,\n",
    "    'test_precision': test_precision,\n",
    "    'test_recall': test_recall,\n",
    "    'test_f1': test_f1\n",
    "}\n",
    "\n",
    "# Final comparison\n",
    "final_results_df = pd.DataFrame(individual_results).T\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL COMPARISON (All Models + Ensemble):\")\n",
    "print(\"=\"*70)\n",
    "print(final_results_df.sort_values('test_accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ba4a79",
   "metadata": {},
   "source": [
    "## 13. Visualize Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e2a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "metrics = ['test_accuracy', 'test_precision', 'test_recall', 'test_f1']\n",
    "titles = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "colors = ['skyblue', 'lightgreen', 'lightcoral', 'plum']\n",
    "\n",
    "for idx, (metric, title, color) in enumerate(zip(metrics, titles, colors)):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # Sort by metric\n",
    "    sorted_df = final_results_df.sort_values(metric, ascending=True)\n",
    "    \n",
    "    # Highlight ensemble\n",
    "    colors_list = [color if name != 'Ensemble' else 'gold' for name in sorted_df.index]\n",
    "    \n",
    "    # Plot\n",
    "    bars = ax.barh(sorted_df.index, sorted_df[metric], color=colors_list, edgecolor='black')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 0.005, bar.get_y() + bar.get_height()/2, \n",
    "                f'{width:.4f}', ha='left', va='center', fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel(title)\n",
    "    ax.set_title(f'{title} Comparison')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    ax.set_xlim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODEL_SAVE_PATH / 'model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadd24c4",
   "metadata": {},
   "source": [
    "## 14. Save Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2bc08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ensemble model\n",
    "torch.save(ensemble_model.state_dict(), MODEL_SAVE_PATH / 'ensemble_model.pth')\n",
    "print(f\"Ensemble model saved to: {MODEL_SAVE_PATH / 'ensemble_model.pth'}\")\n",
    "\n",
    "# Save individual models\n",
    "for model_name, model in trained_models.items():\n",
    "    torch.save(model.state_dict(), MODEL_SAVE_PATH / f'{model_name}_final.pth')\n",
    "print(f\"Individual models saved\")\n",
    "\n",
    "# Save results to CSV\n",
    "final_results_df.to_csv(MODEL_SAVE_PATH / 'model_results.csv')\n",
    "print(f\"Results saved to: {MODEL_SAVE_PATH / 'model_results.csv'}\")\n",
    "\n",
    "# Save class mappings\n",
    "with open(MODEL_SAVE_PATH / 'class_mappings.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'class_to_idx': class_to_idx,\n",
    "        'idx_to_class': idx_to_class,\n",
    "        'num_classes': num_classes\n",
    "    }, f, indent=2)\n",
    "print(f\"Class mappings saved to: {MODEL_SAVE_PATH / 'class_mappings.json'}\")\n",
    "\n",
    "# Save training histories\n",
    "with open(MODEL_SAVE_PATH / 'training_histories.json', 'w') as f:\n",
    "    # Convert numpy arrays to lists for JSON serialization\n",
    "    histories_json = {}\n",
    "    for model_name, history in training_histories.items():\n",
    "        histories_json[model_name] = {\n",
    "            key: [float(v) for v in values] \n",
    "            for key, values in history.items()\n",
    "        }\n",
    "    json.dump(histories_json, f, indent=2)\n",
    "print(f\"Training histories saved to: {MODEL_SAVE_PATH / 'training_histories.json'}\")\n",
    "\n",
    "print(\"\\nAll models and results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2dac7c",
   "metadata": {},
   "source": [
    "## 15. Summary và Kết luận"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f74f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \"*20 + \"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nDataset: PlantVillage\")\n",
    "print(f\"Total Classes: {num_classes}\")\n",
    "print(f\"Total Images: {len(X_paths)}\")\n",
    "print(f\"  - Train: {len(X_train)}\")\n",
    "print(f\"  - Validation: {len(X_val)}\")\n",
    "print(f\"  - Test: {len(X_test)}\")\n",
    "\n",
    "print(f\"\\nModels Trained:\")\n",
    "for model_name in ENSEMBLE_MODELS:\n",
    "    print(f\"  - {model_name}\")\n",
    "\n",
    "print(f\"\\nBest Individual Model:\")\n",
    "best_individual = final_results_df[final_results_df.index != 'Ensemble'].sort_values(\n",
    "    'test_accuracy', ascending=False\n",
    ").iloc[0]\n",
    "best_model_name = final_results_df[final_results_df.index != 'Ensemble'].sort_values(\n",
    "    'test_accuracy', ascending=False\n",
    ").index[0]\n",
    "print(f\"  Model: {best_model_name}\")\n",
    "print(f\"  Accuracy: {best_individual['test_accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nEnsemble Model:\")\n",
    "ensemble_acc = final_results_df.loc['Ensemble', 'test_accuracy']\n",
    "print(f\"  Accuracy: {ensemble_acc:.4f}\")\n",
    "\n",
    "improvement = (ensemble_acc - best_individual['test_accuracy']) * 100\n",
    "if improvement > 0:\n",
    "    print(f\"  Improvement over best individual: +{improvement:.2f}%\")\n",
    "else:\n",
    "    print(f\"  Difference from best individual: {improvement:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Training and Evaluation Complete!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
